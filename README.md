# Papers on Simplicity Bias
---
## Papers
---
| Papers | Link | Code | Published in |
|---|---|---|---|
| In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning | [Paper](https://arxiv.org/abs/1412.6614) | | ICLR 2015 |
| Deep learning generalizes because the parameter-function map is biased towards simple functions | [ArXiV](https://arxiv.org/abs/1805.08522) | - | Pre-print |
| Random deep neural networks are biased towards simple functions | [Paper](https://proceedings.neurips.cc/paper/2019/file/feab05aa91085b7a8012516bc3533958-Paper.pdf) | - | NeurIPS 2019 |
| The Pitfalls of Simplicity Bias in Neural Networks | [Paper](https://proceedings.neurips.cc/paper/2020/file/6cfe0e6127fa25df2a0ef2ae1067d915-Paper.pdf) | [Code](https://github.com/harshays/simplicitybiaspitfalls) | NeurIPS 2020 |
| Simplicity Bias in 1-Hidden Layer Neural Networks | [Paper](https://neurips.cc/virtual/2023/poster/71765) | - | NeurIPS 2023 (Poster) |
| Overcoming Simplicity Bias in Deep Networks using a Feature Sieve | [Paper](https://proceedings.mlr.press/v202/tiwari23a/tiwari23a.pdf) | - | ICML 2023 |
| The Low-Rank Simplicity Bias in Deep Networks | [Paper](https://minyoungg.github.io/overparam/resources/overparam-v3.pdf) | [Code](https://github.com/minyoungg/overparam) | TMLR 2021 |
| Do Input Gradients Highlight Discriminative Features? | [Paper](https://proceedings.neurips.cc/paper_files/paper/2021/file/0fe6a94848e5c68a54010b61b3e94b0e-Paper.pdf) | [Code](https://github.com/harshays/inputgradients)| NeurIPS 2021 |
| Self-supervised debiasing using low rank regularization | [OpenReview](https://openreview.net/forum?id=PHpK5B2iGpq) | - | Pre-print |
| Delving Deep into Simplicity Bias for Long-Tailed Image Recognition | [ArXiv](https://arxiv.org/abs/2302.03264) | - | Pre-print |
| Simplicity Bias in Transformers and their Ability to Learn Sparse Boolean Functions | [Paper](https://aclanthology.org/2023.acl-long.317.pdf) | - | ACL 2023 |
| Evading the Simplicity Bias: Training a Diverse Set of Models Discovers Solutions with Superior OOD Generalization | [Paper](https://ehsanabb.github.io/assets/files/Evading_the_Simplicity_Bias_CVPR_2022_paper.pdf) | | CVPR 20222 |
| Can contrastive learning avoid shortcut solutions? | [Paper](https://proceedings.neurips.cc/paper/2021/file/27934a1f19d678a1377c257b9a780e80-Paper.pdf) | [Code](https://github.com/joshr17/IFM) | NeurIPS 2021 |
| Which Features are Learnt by Contrastive Learning? On the Role of Simplicity Bias in Class Collapse and Feature Suppression | [Paper](https://proceedings.mlr.press/v202/xue23d/xue23d.pdf)| | ICML 2023 |
| Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations | [ArXiV](https://arxiv.org/abs/2204.02937) | - | - |
| Is Last Layer Re-Training Truly Sufficient for Robustness to Spurious Correlations? | [ArXiV](https://arxiv.org/abs/2308.00473) | - | - |
| Shortcut learning in deep neural networks | [Paper](https://www.nature.com/articles/s42256-020-00257-z) [ArXiV](https://arxiv.org/abs/2004.07780) | | Nature Machine Intelligence 2020 |
| Gradient Starvation: A Learning Proclivity in Neural Networks | [Paper](https://arxiv.org/pdf/2011.09468.pdf) | [Code](https://github.com/mpezeshki/Gradient_Starvation) | NeurIPS 2020 |
| SGD on Neural Networks Learns Functions of Increasing Complexity | [Paper](https://dl.acm.org/doi/10.5555/3454287.3454601) | | NeurIPS 2019 |
| Neural networks trained with SGD learn distributions of increasing complexity | [Paper](https://proceedings.mlr.press/v202/refinetti23a/refinetti23a.pdf) | [Code](https://github.com/sgoldt/dist_inc_comp.) | NeurIPS 2023 |
| SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data | [ArXiV](https://arxiv.org/abs/1710.10174) | | Pre-print |
| Intrinsic dimension of data representations in deep neural networks | [Paper](https://proceedings.neurips.cc/paper_files/paper/2019/file/cfcce0621b49c983991ead4c3d4d3b6b-Paper.pdf) | | NeurIPS 2019 |
| Critical Learning Periods in Deep Neural Networks | [ArXiV](https://arxiv.org/abs/1711.08856) | [Code](https://github.com/uw-mad-dash/Accordion) | Pre-print |
| Hierarchical nucleation in deep neural networks | [Paper](https://proceedings.neurips.cc/paper/2020/file/54f3bc04830d762a3b56a789b6ff62df-Paper.pdf) | [Code](https://github.com/diegodoimo/hierarchical_nucleation) | NeurIPS 2020 |
| Do deep neural networks learn shallow learnable examples first? | [Paper](https://openreview.net/forum?id=HkxHv4rn24) | [Code](https://github.com/karttikeya/Shallow_to_Deep/) | ICML 2020 |
| A closer look at memorization in deep networks | [Paper](https://proceedings.mlr.press/v70/arpit17a/arpit17a.pdf) | | ICML 2017 |
| What shapes feature representations? Exploring datasets, architectures, and training | [Paper](https://proceedings.nips.cc/paper/2020/file/71e9c6620d381d60196ebe694840aaaa-Paper.pdf) | | NeurIPS 2020 |
| High-Frequency Component Helps Explain the Generalization of Convolutional Neural Networks | [Paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_High-Frequency_Component_Helps_Explain_the_Generalization_of_Convolutional_Neural_Networks_CVPR_2020_paper.pdf) | [Code](https://github.com/HaohanWang/HFC) | CVPR 2020 |
| Adversarial Perturbations Are Not So Weird: Entanglement of Robust and Non-Robust Features in Neural Network Classifiers | [ArXiV](https://arxiv.org/pdf/2102.05110.pdf) | | Pre-print |
| Just Train Twice: Improving Group Robustness without Training Group Information | [Paper](http://proceedings.mlr.press/v139/liu21f/liu21f.pdf) | [Code](https://github.com/anniesch/jtt) | ICML 2021 |
---
## Blogs
---
| Blog | Link |
|---|---|
| A brief note on Simplicity Bias | [Link](https://www.lesswrong.com/posts/Gyggp2DJRMRLSnhid/a-brief-note-on-simplicity-bias-1) |
| Neural networks are fundamentally (almost) Bayesian | [Link](https://towardsdatascience.com/neural-networks-are-fundamentally-bayesian-bee9a172fad8) |
| Deep Neural Networks are biased, at initialisation, towards simple functions | [Link](https://towardsdatascience.com/deep-neural-networks-are-biased-at-initialisation-towards-simple-functions-a63487edcb99) |
